# Backend - French Sovereign Chatbot

Backend FastAPI avec API compatible Ollama pour Mistral AI.

## ğŸ—ï¸ Architecture

```
backend/
â”œâ”€â”€ api/                    # Routes API
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ollama_routes.py   # Routes Ollama-compatible
â”œâ”€â”€ models/                 # ModÃ¨les Pydantic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ schemas.py         # SchÃ©mas de validation
â”œâ”€â”€ services/               # Logique mÃ©tier
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ mistral_service.py # Service Mistral AI
â”œâ”€â”€ config.py              # Configuration centralisÃ©e
â”œâ”€â”€ main.py                # Point d'entrÃ©e FastAPI
â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â””â”€â”€ Dockerfile            # Image Docker optimisÃ©e
```

## ğŸš€ DÃ©marrage rapide

### Avec Docker (recommandÃ©)

```bash
# Depuis la racine du projet
docker-compose up -d backend
```

### Mode dÃ©veloppement

```bash
cd backend

# CrÃ©er un environnement virtuel
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
.\venv\Scripts\activate   # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt

# Configurer l'environnement
export MISTRAL_API_KEY=your_key_here

# Lancer le serveur
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

## ğŸ“ Variables d'environnement

| Variable | Description | Requis |
|----------|-------------|--------|
| `MISTRAL_API_KEY` | ClÃ© API Mistral AI | âœ… Oui |
| `FRONTEND_URL` | URL du frontend pour CORS | âŒ Non (default: localhost:3000) |

## ğŸ”Œ Endpoints

### Health Check
- `GET /` - Status gÃ©nÃ©ral
- `GET /health` - Health check dÃ©taillÃ©

### Ollama-compatible API
- `GET /api/tags` - Liste des modÃ¨les
- `POST /api/generate` - GÃ©nÃ©ration de texte
- `POST /api/chat` - Chat conversationnel
- `POST /api/pull` - Mock endpoint

**Documentation interactive** :
- Swagger UI : http://localhost:8000/docs
- ReDoc : http://localhost:8000/redoc

## ğŸ§ª Tests

```bash
# Test de santÃ©
curl http://localhost:8000/

# Liste des modÃ¨les
curl http://localhost:8000/api/tags

# Test chat
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mistral-large",
    "messages": [{"role": "user", "content": "Hello!"}],
    "stream": true
  }'
```

## ğŸ­ Production

### Dockerfile optimisÃ©

Le Dockerfile utilise :
- **Multi-stage build** pour rÃ©duire la taille
- **Layer caching** optimal (requirements d'abord)
- **Non-root user** pour la sÃ©curitÃ©
- **Health checks** configurÃ©s

### Build manuel

```bash
docker build -t chatbot-backend .
docker run -d -p 8000:8000 \
  -e MISTRAL_API_KEY=your_key \
  chatbot-backend
```

## ğŸ”§ Configuration

Tous les paramÃ¨tres sont centralisÃ©s dans `config.py` :
- URLs des APIs
- Mapping des modÃ¨les
- CORS origins
- ModÃ¨les disponibles

## ğŸ“Š Performance

- **Workers** : 1 par dÃ©faut (ajuster selon CPU)
- **Timeout** : 60s pour Mistral API
- **Streaming** : Support complet SSE â†’ NDJSON

## ğŸ› Debugging

```bash
# Logs dÃ©taillÃ©s
uvicorn main:app --log-level debug

# Recharger automatiquement
uvicorn main:app --reload

# Tester sans Docker
python main.py
```

## ğŸ“¦ DÃ©pendances principales

- `fastapi` - Framework web
- `uvicorn` - Serveur ASGI
- `httpx` - Client HTTP async
- `pydantic` - Validation de donnÃ©es
- `python-dotenv` - Variables d'environnement

## ğŸ¤ Contribution

Structure Ã  respecter :
1. **api/** - Routes uniquement, pas de logique
2. **services/** - Logique mÃ©tier isolÃ©e
3. **models/** - Validation avec Pydantic
4. **config.py** - Configuration centralisÃ©e

## ğŸ“„ Licence

Voir LICENSE Ã  la racine du projet.